{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504afc0a",
   "metadata": {},
   "source": [
    "# Web Scraping Project Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c5c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049a911",
   "metadata": {},
   "source": [
    "#### Q1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a281392f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfl-h2\"><span id=\"From_today.27s_featured_list\"></span><span class=\"mw-headline\" id=\"From_today's_featured_list\">From today's featured list</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>,\n",
       " <h2>Navigation menu</h2>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
       " <span>Personal tools</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
       " <span>Namespaces</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
       " <span>Variants</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
       " <span>Views</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
       " <span>More</span>\n",
       " </h3>,\n",
       " <h3>\n",
       " <label for=\"searchInput\">Search</label>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
       " <span>Navigation</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
       " <span>Contribute</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
       " <span>Tools</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
       " <span>Print/export</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
       " <span>In other projects</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
       " <span>Languages</span>\n",
       " </h3>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def header_tags(url):\n",
    "    a = requests.get(url)\n",
    "    src = a.content\n",
    "    soup = BeautifulSoup(src,'html.parser')\n",
    "    return soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"])\n",
    "\n",
    "# Calling Function\n",
    "header_tags('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdef0ce",
   "metadata": {},
   "source": [
    "#### Q2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895b0dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Years of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption(1994)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather(1972)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II(1974)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight(2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men(1957)</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Singin' in the Rain(1952)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>North by Northwest(1959)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Eternal Sunshine of the Spotless Mind(2004)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Idi i smotri(1985)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ladri di biciclette(1948)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Names  Ratings  Years of release\n",
       "0                 The Shawshank Redemption(1994)      9.2              1994\n",
       "1                            The Godfather(1972)      9.1              1972\n",
       "2                   The Godfather: Part II(1974)      9.0              1974\n",
       "3                          The Dark Knight(2008)      9.0              2008\n",
       "4                             12 Angry Men(1957)      8.9              1957\n",
       "..                                           ...      ...               ...\n",
       "95                     Singin' in the Rain(1952)      8.3              1952\n",
       "96                      North by Northwest(1959)      8.3              1959\n",
       "97   Eternal Sunshine of the Spotless Mind(2004)      8.3              2004\n",
       "98                            Idi i smotri(1985)      8.3              1985\n",
       "99                     Ladri di biciclette(1948)      8.3              1948\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def IMDB_top_100(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    names = []\n",
    "    ratings=[]\n",
    "    years = []\n",
    "    for i in soup.find_all('td', class_ = 'titleColumn'):\n",
    "        names.append(i.text.replace('\\n', \"\")[14:-6])\n",
    "    for i in soup.find_all('td', class_ = 'ratingColumn imdbRating'):\n",
    "        ratings.append(float(i.text.replace('\\n', \"\")))\n",
    "    for i in soup.find_all('span', class_='secondaryInfo'):\n",
    "        years.append(int(i.text[1:-1]))\n",
    "    df = pd.DataFrame({'Names':names[:100], 'Ratings':ratings[:100], 'Years of release':years[:100]})\n",
    "    return df\n",
    "#calling function\n",
    "IMDB_top_100('https://www.imdb.com/chart/top/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f12fb4",
   "metadata": {},
   "source": [
    "#### Q3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f505a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Years of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drishyam 2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chhichhore</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virumandi</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PK</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Iqbal</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Names  Ratings  Years of release\n",
       "0             Pather Panchali      8.5              1955\n",
       "1                     Nayakan      8.5              1987\n",
       "2                  Anbe Sivam      8.5              2003\n",
       "3           Pariyerum Perumal      8.5              2018\n",
       "4                  Drishyam 2      8.5              2021\n",
       "..                        ...      ...               ...\n",
       "95   Uri: The Surgical Strike      8.1              2018\n",
       "96                 Chhichhore      8.1              2019\n",
       "97                  Virumandi      8.1              2004\n",
       "98                         PK      8.1              2014\n",
       "99                      Iqbal      8.1              2005\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Indian_IMDB_top_100(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    names = []\n",
    "    ratings=[]\n",
    "    years = []\n",
    "    for i in soup.find_all('td', class_ = 'titleColumn'):\n",
    "        names.append(i.text.replace('\\n', \"\")[14:-6])\n",
    "    for i in soup.find_all('td', class_ = 'ratingColumn imdbRating'):\n",
    "        ratings.append(float(i.text.replace('\\n', \"\")))\n",
    "    for i in soup.find_all('span', class_='secondaryInfo'):\n",
    "        years.append(int(i.text[1:-1]))\n",
    "    df = pd.DataFrame({'Names':names[:100], 'Ratings':ratings[:100], 'Years of release':years[:100]})\n",
    "    return df\n",
    "Indian_IMDB_top_100('https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=8a7876cd-2844-4017-846a-2c0876945b7b&pf_rd_r=ZHXFB84HZG5YP7EWJ71C&pf_rd_s=right-5&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_india_tr_rhs_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db411659",
   "metadata": {},
   "source": [
    "#### Q4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edaf7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book names</th>\n",
       "      <th>Author names</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Book reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You People</td>\n",
       "      <td>Nikita Lalwani</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "      <td>The incident that gives You People its title o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>★ Ship in a Bottle</td>\n",
       "      <td>Andrew Prahin</td>\n",
       "      <td>Children's / Children's Picture Book</td>\n",
       "      <td>Poor Mouse. She lives with Cat, and needless t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tokyo Ever After</td>\n",
       "      <td>Emiko Jean</td>\n",
       "      <td>YA / YA Fiction</td>\n",
       "      <td>There’s no shortage of YA novels in which a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Kingdoms</td>\n",
       "      <td>Natasha Pulley</td>\n",
       "      <td>Fiction / Speculative Fiction</td>\n",
       "      <td>When Joe Tournier steps off a train from Glasg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Yorkers</td>\n",
       "      <td>Craig Taylor, Cast</td>\n",
       "      <td>Audio / Nonfiction / Culture</td>\n",
       "      <td>“Part of loving New York is just mourning the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Book names        Author names  \\\n",
       "0          You People      Nikita Lalwani   \n",
       "1  ★ Ship in a Bottle       Andrew Prahin   \n",
       "2    Tokyo Ever After          Emiko Jean   \n",
       "3        The Kingdoms      Natasha Pulley   \n",
       "4         New Yorkers  Craig Taylor, Cast   \n",
       "\n",
       "                                 Genres  \\\n",
       "0            Fiction / Literary Fiction   \n",
       "1  Children's / Children's Picture Book   \n",
       "2                       YA / YA Fiction   \n",
       "3         Fiction / Speculative Fiction   \n",
       "4          Audio / Nonfiction / Culture   \n",
       "\n",
       "                                        Book reviews  \n",
       "0  The incident that gives You People its title o...  \n",
       "1  Poor Mouse. She lives with Cat, and needless t...  \n",
       "2  There’s no shortage of YA novels in which a co...  \n",
       "3  When Joe Tournier steps off a train from Glasg...  \n",
       "4  “Part of loving New York is just mourning the ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bookpage():\n",
    "    r = requests.get('https://bookpage.com/reviews')\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    urls=[]\n",
    "    url_tags = soup.find_all('div', class_='row-fluid article-row')\n",
    "    for i in url_tags[0:5]:\n",
    "        urls.append(i.find('h4').find_all('a')[0]['href'])\n",
    "    bookname = []\n",
    "    authorname = []\n",
    "    genre = []\n",
    "    bookreview = []\n",
    "    for url in urls:\n",
    "        r = requests.get('https://bookpage.com'+url)\n",
    "        soup = BeautifulSoup(r.content,'html.parser')\n",
    "        bookname.append(soup.find('h1', class_='italic').text.replace('\\n',\"\"))\n",
    "        authorname.append(soup.find('h4', class_='sans').text.replace('\\n',\"\"))\n",
    "        genre.append(soup.find('p', class_='genre-links').text.replace('\\n',\"\"))\n",
    "        bookreview.append(soup.find('div', class_='article-body').text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({'Book names':bookname,\n",
    "                       'Author names':authorname,\n",
    "                       'Genres':genre,\n",
    "                       'Book reviews':bookreview })\n",
    "    return df\n",
    "bookpage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfb3245",
   "metadata": {},
   "source": [
    "#### Q5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.                                 \n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.                                             \n",
    "iii) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "#### Solution:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ade74227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>26</td>\n",
       "      <td>2,413</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>23</td>\n",
       "      <td>1,733</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Ratings\n",
       "0   New Zealand      17  2,054     121\n",
       "1     Australia      25  2,945     118\n",
       "2         India      29  3,344     115\n",
       "3       England      27  3,100     115\n",
       "4  South Africa      20  2,137     107\n",
       "5      Pakistan      24  2,323      97\n",
       "6    Bangladesh      26  2,413      93\n",
       "7   West Indies      27  2,222      82\n",
       "8     Sri Lanka      23  1,733      75\n",
       "9   Afghanistan      17  1,054      62"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Top_10_ODI_team(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content,'html.parser')\n",
    "    teams = []\n",
    "    matches = []\n",
    "    points = []\n",
    "    ratings = []\n",
    "    for i in soup.find_all('span',attrs={'u-hide-phablet'}):\n",
    "        teams.append(i.text)\n",
    "    matches.append(soup.find('td',class_='rankings-block__banner--matches').text)\n",
    "    points.append(soup.find('td',class_='rankings-block__banner--points').text)\n",
    "    ratings.append(soup.find('td', class_='rankings-block__banner--rating u-text-right').text.replace('\\n',\"\").strip())\n",
    "    count=0\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell u-center-text'))[:18]:\n",
    "        if count%2==0:\n",
    "            matches.append(i.text)\n",
    "        else:\n",
    "            points.append(i.text)\n",
    "        count+=1\n",
    "    for i in soup.find_all('td', class_='table-body__cell u-text-right rating'):\n",
    "        ratings.append(int(i.text.replace('\\n',\"\").strip()))\n",
    "    df = pd.DataFrame({'Teams': teams[:10], \n",
    "                       'Matches':matches,\n",
    "                       'Points': points,\n",
    "                       'Ratings': ratings[:10]})\n",
    "    return df\n",
    "Top_10_ODI_team('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a436c",
   "metadata": {},
   "source": [
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00f1c963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name Team points\n",
       "0           Babar Azam  PAK    865\n",
       "1          Virat Kohli  IND    857\n",
       "2         Rohit Sharma  IND    825\n",
       "3          Ross Taylor   NZ    801\n",
       "4          Aaron Finch  AUS    791\n",
       "5       Jonny Bairstow  ENG    785\n",
       "6         Fakhar Zaman  PAK    778\n",
       "7  Francois du Plessis   SA    778\n",
       "8         David Warner  AUS    773\n",
       "9            Shai Hope   WI    773"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Top_10_ODI_batsman(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    team=[]\n",
    "    point=[]\n",
    "    name.append(soup.find('div',class_=\"rankings-block__banner--name-large\").text.replace('\\n',\"\"))\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell rankings-table__name name'))[:9]:\n",
    "        name.append(i.text.replace('\\n',''))\n",
    "    team.append(soup.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n',\"\"))\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell nationality-logo rankings-table__team'))[:9]:\n",
    "        team.append(i.text.replace('\\n',''))\n",
    "    point.append(soup.find('div',class_=\"rankings-block__banner--rating\").text)\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell rating'))[:9]:\n",
    "        point.append(i.text)\n",
    "    df=pd.DataFrame({'Name': name,\n",
    "                     'Team':team,\n",
    "                     'points':point})\n",
    "    return df\n",
    "\n",
    "\n",
    "# Calling Function\n",
    "Top_10_ODI_batsman(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff043a0b",
   "metadata": {},
   "source": [
    "iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9797746d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Team points\n",
       "0        Trent Boult   NZ    737\n",
       "1       Mehedi Hasan  BAN    725\n",
       "2   Mujeeb Ur Rahman  AFG    708\n",
       "3         Matt Henry   NZ    691\n",
       "4     Jasprit Bumrah  IND    690\n",
       "5      Kagiso Rabada   SA    666\n",
       "6       Chris Woakes  ENG    665\n",
       "7     Josh Hazlewood  AUS    660\n",
       "8  Mustafizur Rahman  BAN    652\n",
       "9        Pat Cummins  AUS    646"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Top_10_ODI_bowler(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    team=[]\n",
    "    point=[]\n",
    "    name.append(soup.find('div',attrs={\"rankings-block__banner--name-large\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rankings-table__name name'}))[:9]:\n",
    "        name.append(i.text.replace('\\n',''))\n",
    "    team.append(soup.find('div',attrs={\"rankings-block__banner--nationality\"}).text.replace('\\n',\"\"))\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell nationality-logo rankings-table__team'}))[:9]:\n",
    "        team.append(i.text.replace('\\n',''))\n",
    "    point.append(soup.find('div',attrs={\"rankings-block__banner--rating\"}).text)\n",
    "    for i in list(soup.find_all('td',attrs={'table-body__cell rating'}))[:9]:\n",
    "        point.append(i.text)\n",
    "    df=pd.DataFrame({'Name': name,\n",
    "                     'Team':team,\n",
    "                     'points':point})\n",
    "    return df\n",
    "\n",
    "# Calling Function\n",
    "Top_10_ODI_batsman(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b63882",
   "metadata": {},
   "source": [
    "#### Q6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.                                  \n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.                                                \n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating. \n",
    "\n",
    "#### Solutions:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bd53c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches Points Ratings\n",
       "0     Australia      18  2,955     164\n",
       "1  South Africa      24  2,828     118\n",
       "2       England      17  1,993     117\n",
       "3         India      20  2,226     111\n",
       "4   New Zealand      21  1,947      93\n",
       "5   West Indies      12  1,025      85\n",
       "6      Pakistan      15  1,101      73\n",
       "7    Bangladesh       5    306      61\n",
       "8     Sri Lanka      11    519      47\n",
       "9       Ireland       2     25      13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Top_10_Women_ODI_team(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content,'html.parser')\n",
    "    teams = []\n",
    "    matches = []\n",
    "    points = []\n",
    "    ratings = []\n",
    "    for i in soup.find_all('span',class_='u-hide-phablet'):\n",
    "        teams.append(i.text)\n",
    "    matches.append(soup.find('td',class_='rankings-block__banner--matches').text)\n",
    "    points.append(soup.find('td',class_='rankings-block__banner--points').text)\n",
    "    ratings.append(soup.find('td', class_='rankings-block__banner--rating u-text-right').text.replace('\\n',\"\").strip())\n",
    "    count=0\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell u-center-text'))[:18]:\n",
    "        if count%2==0:\n",
    "            matches.append(i.text)\n",
    "        else:\n",
    "            points.append(i.text)\n",
    "        count+=1\n",
    "    for i in soup.find_all('td', class_='table-body__cell u-text-right rating'):\n",
    "        ratings.append(int(i.text.replace('\\n',\"\").strip()))\n",
    "    df = pd.DataFrame({'Teams': teams[:10], \n",
    "                       'Matches':matches,\n",
    "                       'Points': points,\n",
    "                       'Ratings': ratings[:10]})\n",
    "    return df\n",
    "Top_10_Women_ODI_team('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6db97",
   "metadata": {},
   "source": [
    "ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d872d04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Team points\n",
       "0     Tammy Beaumont  ENG    765\n",
       "1        Lizelle Lee   SA    758\n",
       "2       Alyssa Healy  AUS    756\n",
       "3    Stafanie Taylor   WI    746\n",
       "4        Meg Lanning  AUS    723\n",
       "5  Amy Satterthwaite   NZ    715\n",
       "6    Smriti Mandhana  IND    710\n",
       "7        Mithali Raj  IND    709\n",
       "8     Natalie Sciver  ENG    685\n",
       "9    Laura Wolvaardt   SA    683"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Top_10_Women_ODI_player(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    team=[]\n",
    "    point=[]\n",
    "    name.append(soup.find('div',class_=\"rankings-block__banner--name-large\").text)\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell rankings-table__name name'))[:9]:\n",
    "        name.append(i.text.replace('\\n',''))\n",
    "    team.append(soup.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n', \"\"))\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell nationality-logo rankings-table__team'))[:9]:\n",
    "        team.append(i.text.replace('\\n',''))\n",
    "    point.append(soup.find('div',class_=\"rankings-block__banner--rating\").text)\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell rating'))[:9]:\n",
    "        point.append(i.text)\n",
    "    df=pd.DataFrame({'Name': name,\n",
    "                     'Team':team,\n",
    "                     'points':point})\n",
    "    return df\n",
    "\n",
    "# Calling Function\n",
    "Top_10_Women_ODI_player(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1120ef",
   "metadata": {},
   "source": [
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01e755ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name Team points\n",
       "0    Marizanne Kapp   SA    418\n",
       "1      Ellyse Perry  AUS    418\n",
       "2   Stafanie Taylor   WI    410\n",
       "3    Natalie Sciver  ENG    349\n",
       "4     Deepti Sharma  IND    343\n",
       "5     Jess Jonassen  AUS    307\n",
       "6  Ashleigh Gardner  AUS    252\n",
       "7  Dane van Niekerk   SA    243\n",
       "8     Sophie Devine   NZ    242\n",
       "9       Amelia Kerr   NZ    236"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Top_10_Women_ODI_Allrounder(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    name=[]\n",
    "    team=[]\n",
    "    point=[]\n",
    "    name.append(soup.find('div',class_=\"rankings-block__banner--name-large\").text)\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell rankings-table__name name'))[:9]:\n",
    "        name.append(i.text.replace('\\n',''))\n",
    "    team.append(soup.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n',\"\"))\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell nationality-logo rankings-table__team'))[:9]:\n",
    "        team.append(i.text.replace('\\n',''))\n",
    "    point.append(soup.find('div',class_=\"rankings-block__banner--rating\").text)\n",
    "    for i in list(soup.find_all('td',class_='table-body__cell rating'))[:9]:\n",
    "        point.append(i.text)\n",
    "    df=pd.DataFrame({'Name': name,\n",
    "                     'Team':team,\n",
    "                     'points':point})\n",
    "    return df\n",
    "\n",
    "# Calling function\n",
    "Top_10_Women_ODI_Allrounder(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75399f91",
   "metadata": {},
   "source": [
    "#### Q7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e1d5713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://www.amazon.in/s?k=mobile+under+20000&rh=p_36%3A-2000000&qid=1622699513&rnid=1318502031&ref=sr_nr_p_36_4')\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b631c28",
   "metadata": {},
   "source": [
    "The ratings of the Amazon.in cannot be scraped by normal method as we are getting status code as 503, Selenium is needed for it which is not yet taught to us. Hence skiping this question as told by Sajid Choudhary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8416d7",
   "metadata": {},
   "source": [
    "#### Q8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "359dde0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Short_description</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>Mostly Cloudythen MostlySunny andBreezy</td>\n",
       "      <td>High: 63 °F</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Partly Cloudyand Breezythen MostlyCloudy</td>\n",
       "      <td>Low: 53 °F</td>\n",
       "      <td>Mostly cloudy, with a low around 53. Breezy, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Partly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 68 °F</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "      <td>Low: 53 °F</td>\n",
       "      <td>Mostly clear, with a low around 53. Breezy, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 67 °F</td>\n",
       "      <td>Mostly sunny, with a high near 67. Breezy, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Mostly Clearand Breezythen MostlyClear</td>\n",
       "      <td>Low: 53 °F</td>\n",
       "      <td>Mostly clear, with a low around 53. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 68 °F</td>\n",
       "      <td>Sunny, with a high near 68.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SaturdayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Low: 52 °F</td>\n",
       "      <td>Mostly clear, with a low around 52.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 67 °F</td>\n",
       "      <td>Sunny, with a high near 67.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Period                         Short_description  Temperature  \\\n",
       "0          Today   Mostly Cloudythen MostlySunny andBreezy  High: 63 °F   \n",
       "1        Tonight  Partly Cloudyand Breezythen MostlyCloudy   Low: 53 °F   \n",
       "2       Thursday          Partly Sunnythen Sunnyand Breezy  High: 68 °F   \n",
       "3  ThursdayNight   Mostly Clearand Breezythen PartlyCloudy   Low: 53 °F   \n",
       "4         Friday          Mostly Sunnythen Sunnyand Breezy  High: 67 °F   \n",
       "5    FridayNight    Mostly Clearand Breezythen MostlyClear   Low: 53 °F   \n",
       "6       Saturday                                     Sunny  High: 68 °F   \n",
       "7  SaturdayNight                              Mostly Clear   Low: 52 °F   \n",
       "8         Sunday                                     Sunny  High: 67 °F   \n",
       "\n",
       "                                         Description  \n",
       "0  Mostly cloudy, then gradually becoming sunny, ...  \n",
       "1  Mostly cloudy, with a low around 53. Breezy, w...  \n",
       "2  Mostly cloudy, then gradually becoming sunny, ...  \n",
       "3  Mostly clear, with a low around 53. Breezy, wi...  \n",
       "4  Mostly sunny, with a high near 67. Breezy, wit...  \n",
       "5       Mostly clear, with a low around 53. Breezy.   \n",
       "6                        Sunny, with a high near 68.  \n",
       "7                Mostly clear, with a low around 52.  \n",
       "8                        Sunny, with a high near 67.  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weather(url):\n",
    "    r=requests.get(url)\n",
    "    soup=BeautifulSoup(r.content,'html.parser')\n",
    "    period=[]\n",
    "    short_desc=[]\n",
    "    temp=[]\n",
    "    desc=[]\n",
    "    for i in soup.find_all('p',class_='period-name'):\n",
    "        period.append(i.text)\n",
    "    for i in soup.find_all('p',class_='short-desc'):\n",
    "        short_desc.append(i.text)\n",
    "    for i in soup.find_all('p',class_='short-desc'):\n",
    "        if i.next_sibling is not None:\n",
    "            temp.append(i.next_sibling.text)\n",
    "        else:\n",
    "            temp.append(' ')\n",
    "    for i in soup.find_all('div',class_=\"col-sm-10 forecast-text\"):\n",
    "        desc.append(i.text)\n",
    "    df=pd.DataFrame({\"Period\":period,\n",
    "                     \"Short_description\":short_desc,\n",
    "                     \"Temperature\":temp,\n",
    "                     \"Description\":desc[:9]})\n",
    "    return df\n",
    "weather('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YLc5FKgzYb4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7788a",
   "metadata": {},
   "source": [
    "#### Q9. Write a python program to scrape fresher job listing from 'https://internshala.com/'. It should include job title, company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48842b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Research And Communications Associate</td>\n",
       "      <td>Institute For Governance, Policies &amp; Politics</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>2 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ProtonAutoML</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>2 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Django Developer</td>\n",
       "      <td>Markytics</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>2 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>MiM-Essay</td>\n",
       "      <td>5 - 6.5 LPA</td>\n",
       "      <td>2 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Wondermail</td>\n",
       "      <td>4 - 7 LPA</td>\n",
       "      <td>1 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Full Stack Developer (MERN)</td>\n",
       "      <td>Project Tinker</td>\n",
       "      <td>4 - 7.2 LPA</td>\n",
       "      <td>1 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Kaizen Academy</td>\n",
       "      <td>4.5 - 6 LPA</td>\n",
       "      <td>1 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sales Development Representative</td>\n",
       "      <td>Amigobulls</td>\n",
       "      <td>5.5 - 6.5 LPA</td>\n",
       "      <td>1 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>Underground Movement LLP</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>1 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Operations Executive</td>\n",
       "      <td>Alphacore Technologies Private Limited</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>1 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Ruhcom Enterprises Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>1 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Admission Counselor (Sales)</td>\n",
       "      <td>Sky Education Group</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sales And Business Development Analyst</td>\n",
       "      <td>Mo's F&amp;B Group</td>\n",
       "      <td>3 - 3.1 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Growth Hacking Digital Marketer</td>\n",
       "      <td>Sleep Love</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Junior Node.js Developer</td>\n",
       "      <td>Askadmissions.ai</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Junior Digital Marketing Executive</td>\n",
       "      <td>Krivy</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iOS App Developer</td>\n",
       "      <td>Ascentspark Software Private Limited</td>\n",
       "      <td>3.6 - 7 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Food Journalist</td>\n",
       "      <td>Truffle Nation</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>Habitate Technologies Private Limited</td>\n",
       "      <td>5.2 - 7 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>SoluLab</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>28 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>SoluLab</td>\n",
       "      <td>3 - 4.2 LPA</td>\n",
       "      <td>28 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Associate Full Stack Developer</td>\n",
       "      <td>REPOZITORY TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Beehive Academy India</td>\n",
       "      <td>4.2 - 8.2 LPA</td>\n",
       "      <td>28 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Product Marketer</td>\n",
       "      <td>Bip</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>27 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Tabeazy</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>27 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Associate - Business Development</td>\n",
       "      <td>Leverage Edu</td>\n",
       "      <td>3.6 LPA</td>\n",
       "      <td>27 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Research Analyst (Economics)</td>\n",
       "      <td>DEX-DEFT Research And Consulting OPC Private L...</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>30 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>AIMonk Labs Technology Limited</td>\n",
       "      <td>5 - 6.5 LPA</td>\n",
       "      <td>27 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Kasper Consulting Private Limited</td>\n",
       "      <td>3.25 - 4 LPA</td>\n",
       "      <td>26 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge</td>\n",
       "      <td>3.75 LPA</td>\n",
       "      <td>26 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>PEPKIDZ LEARNING</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>25 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Full Stack Software Engineer</td>\n",
       "      <td>Flair Labs</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>25 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>Little Big Things</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>25 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>CrewKarma</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Codfirm</td>\n",
       "      <td>5 - 8 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>WebMOBI</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>TMBill Software</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Junior Sales Associate</td>\n",
       "      <td>Kraftshala</td>\n",
       "      <td>4 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Digital Marketing Specialist</td>\n",
       "      <td>Black Jack</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>24 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Android App Developer</td>\n",
       "      <td>Storlyy</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>23 Jun' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job Title  \\\n",
       "0           Research And Communications Associate    \n",
       "1                                  Data Scientist    \n",
       "2                   Data Science Django Developer    \n",
       "3                       Corporate Sales Associate    \n",
       "4                            Full Stack Developer    \n",
       "5                     Full Stack Developer (MERN)    \n",
       "6                  Business Development Executive    \n",
       "7                Sales Development Representative    \n",
       "8                                Graphic Designer    \n",
       "9                            Operations Executive    \n",
       "10                 Business Development Executive    \n",
       "11                    Admission Counselor (Sales)    \n",
       "12         Sales And Business Development Analyst    \n",
       "13                Growth Hacking Digital Marketer    \n",
       "14                       Junior Node.js Developer    \n",
       "15             Junior Digital Marketing Executive    \n",
       "16                              iOS App Developer    \n",
       "17                                Food Journalist    \n",
       "18                      Junior Software Developer    \n",
       "19                           Full Stack Developer    \n",
       "20                               Business Analyst    \n",
       "21                 Associate Full Stack Developer    \n",
       "22                            Full Stack Engineer    \n",
       "23                               Product Marketer    \n",
       "24                 Business Development Executive    \n",
       "25               Associate - Business Development    \n",
       "26                   Research Analyst (Economics)    \n",
       "27                      Machine Learning Engineer    \n",
       "28                               Business Analyst    \n",
       "29  Business Development Executive (Inside Sales)    \n",
       "30                 Business Development Associate    \n",
       "31                   Full Stack Software Engineer    \n",
       "32                  Associate Front End Developer    \n",
       "33                   Talent Acquisition Executive    \n",
       "34                           Full Stack Developer    \n",
       "35                              Backend Developer    \n",
       "36                           Full Stack Developer    \n",
       "37                         Junior Sales Associate    \n",
       "38                   Digital Marketing Specialist    \n",
       "39                          Android App Developer    \n",
       "\n",
       "                                              Company            CTC  \\\n",
       "0       Institute For Governance, Policies & Politics    3 - 4.5 LPA   \n",
       "1                                        ProtonAutoML    3 - 3.5 LPA   \n",
       "2                                           Markytics    3 - 4.5 LPA   \n",
       "3                                           MiM-Essay    5 - 6.5 LPA   \n",
       "4                                          Wondermail      4 - 7 LPA   \n",
       "5                                      Project Tinker    4 - 7.2 LPA   \n",
       "6                                      Kaizen Academy    4.5 - 6 LPA   \n",
       "7                                          Amigobulls  5.5 - 6.5 LPA   \n",
       "8                            Underground Movement LLP      3 - 5 LPA   \n",
       "9              Alphacore Technologies Private Limited    3 - 3.5 LPA   \n",
       "10                 Ruhcom Enterprises Private Limited          3 LPA   \n",
       "11                                Sky Education Group          3 LPA   \n",
       "12                                     Mo's F&B Group    3 - 3.1 LPA   \n",
       "13                                         Sleep Love    3 - 3.5 LPA   \n",
       "14                                   Askadmissions.ai      3 - 4 LPA   \n",
       "15                                              Krivy          3 LPA   \n",
       "16               Ascentspark Software Private Limited    3.6 - 7 LPA   \n",
       "17                                     Truffle Nation    3 - 4.5 LPA   \n",
       "18              Habitate Technologies Private Limited    5.2 - 7 LPA   \n",
       "19                                            SoluLab      3 - 5 LPA   \n",
       "20                                            SoluLab    3 - 4.2 LPA   \n",
       "21            REPOZITORY TECHNOLOGIES PRIVATE LIMITED    3 - 3.6 LPA   \n",
       "22                              Beehive Academy India  4.2 - 8.2 LPA   \n",
       "23                                                Bip      3 - 6 LPA   \n",
       "24                                            Tabeazy          3 LPA   \n",
       "25                                       Leverage Edu        3.6 LPA   \n",
       "26  DEX-DEFT Research And Consulting OPC Private L...          3 LPA   \n",
       "27                     AIMonk Labs Technology Limited    5 - 6.5 LPA   \n",
       "28                  Kasper Consulting Private Limited   3.25 - 4 LPA   \n",
       "29                                            GREedge       3.75 LPA   \n",
       "30                                   PEPKIDZ LEARNING      3 - 4 LPA   \n",
       "31                                         Flair Labs      3 - 4 LPA   \n",
       "32                                  Little Big Things      3 - 5 LPA   \n",
       "33                                          CrewKarma      3 - 5 LPA   \n",
       "34                                            Codfirm      5 - 8 LPA   \n",
       "35                                            WebMOBI          3 LPA   \n",
       "36                                    TMBill Software          3 LPA   \n",
       "37                                         Kraftshala          4 LPA   \n",
       "38                                         Black Jack      3 - 5 LPA   \n",
       "39                                            Storlyy    3 - 3.5 LPA   \n",
       "\n",
       "    Apply Date  \n",
       "0    2 Jul' 21  \n",
       "1    2 Jul' 21  \n",
       "2    2 Jul' 21  \n",
       "3    2 Jul' 21  \n",
       "4    1 Jul' 21  \n",
       "5    1 Jul' 21  \n",
       "6    1 Jul' 21  \n",
       "7    1 Jul' 21  \n",
       "8    1 Jul' 21  \n",
       "9    1 Jul' 21  \n",
       "10   1 Jul' 21  \n",
       "11  30 Jun' 21  \n",
       "12  30 Jun' 21  \n",
       "13  30 Jun' 21  \n",
       "14  30 Jun' 21  \n",
       "15  30 Jun' 21  \n",
       "16  30 Jun' 21  \n",
       "17  30 Jun' 21  \n",
       "18  30 Jun' 21  \n",
       "19  28 Jun' 21  \n",
       "20  28 Jun' 21  \n",
       "21  30 Jun' 21  \n",
       "22  28 Jun' 21  \n",
       "23  27 Jun' 21  \n",
       "24  27 Jun' 21  \n",
       "25  27 Jun' 21  \n",
       "26  30 Jun' 21  \n",
       "27  27 Jun' 21  \n",
       "28  26 Jun' 21  \n",
       "29  26 Jun' 21  \n",
       "30  25 Jun' 21  \n",
       "31  25 Jun' 21  \n",
       "32  25 Jun' 21  \n",
       "33  24 Jun' 21  \n",
       "34  24 Jun' 21  \n",
       "35  24 Jun' 21  \n",
       "36  24 Jun' 21  \n",
       "37  24 Jun' 21  \n",
       "38  24 Jun' 21  \n",
       "39  23 Jun' 21  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def internshala_jobs(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    job_title = []\n",
    "    company = []\n",
    "    lst = []\n",
    "    CTC = []\n",
    "    Apply_date = []\n",
    "\n",
    "    for i in soup.find_all('div', class_='heading_4_5 profile'):\n",
    "        job_title.append(i.text.replace('\\n', ''))\n",
    "    for i in soup.find_all('div', class_ = 'heading_6 company_name'):\n",
    "        company.append(i.text.replace('\\n', '').strip())\n",
    "    for i in soup.find_all('div', class_ = 'item_body'):\n",
    "        lst.append(i.text.replace('\\n', '').strip())\n",
    "    for i in range(0, len(lst)+1, 3):\n",
    "        if i+2 > len(lst):\n",
    "            break\n",
    "        else:\n",
    "            CTC.append(lst[i+1])\n",
    "            Apply_date.append(lst[i+2])\n",
    "    df = pd.DataFrame({'Job Title': job_title,\n",
    "                       'Company': company,\n",
    "                       'CTC': CTC,\n",
    "                       'Apply Date': Apply_date})\n",
    "    return df\n",
    "internshala_jobs('https://internshala.com/fresher-jobs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
